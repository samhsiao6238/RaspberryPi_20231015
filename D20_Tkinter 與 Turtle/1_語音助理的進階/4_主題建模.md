# 主題建模

<br>

## 簡介

1. 主題建模也是自然語言處理（NLP）中重要的應用領域，旨在從文本集中識別出潛在的主題或模式。

<br>

2. 主題建模是一種統計模型，用於發現大量文件集中的隱藏主題。

<br>

3. 常用的方法包括潛在語義分析（LSA）、潛在狄利克雷分配（LDA）等。


<br>

## 範例代碼

1. 使用 `LDA` 進行主題建模，先將文本集進行向量化，然後用 LDA 模型找出潛在的主題，最後顯示每個主題的主要詞彙。

<br>

2. 安裝套件。

    ```bash
    pip install scikit-learn
    ``` 

<br>

3. 程式碼

    ```python
    # 從 scikit-learn 導入 LDA 模型
    from sklearn.decomposition import LatentDirichletAllocation  
    # 從 scikit-learn 導入文本向量化工具
    from sklearn.feature_extraction.text import CountVectorizer  
    import numpy as np

    # 範例文件集
    docs = [
        "全體國銀的「清呆卡潮」登場，對此金管會主委黃天牧表示，將找大型銀行前來了解兩件事，一是有否在30天前通知民眾要停卡？另一為紅利點數在清卡的同時，是否有作妥適的安排，金管會將主動找大型發卡銀行來開會討論，了解時程與作法是否完整保障到民眾的權益。立委林楚茵今日質詢關注清卡機制的配套作業是否完善；她指出，目前金管會的信用卡業務機構管理辦法規定，銀行在相關權益或優惠變動前60天要通知持卡人，但在正式停卡之前，是否要再行通知，另外，包括停卡之後，卡片裡的紅利、回饋金、里程數等累點，是否就全部沒有，另外她也關注是否影響到卡友的信用評等？銀行局長莊琇媛則回應，目前的確未明文規定，停卡之前最晚何時要通知持卡人，因此仍回歸銀行的契約規定；若以業界普遍作法來看，多半是在停卡之前30天通知。至於紅利積點是否一併被取消，莊琇媛表示會向銀行進一步了解。據了解，現在銀行作法各家不一，但多半會要求卡戶在清卡之前，就要用掉全部的紅利點數，否則到清卡時，就一切「歸零」。林楚茵則認為，當愈來愈多銀行加入清卡行列之後，金管會應該提出統一規範，以免持卡人權益被傷害。",
        "8769天的等待，龍迷終於流下喜悅的淚水。味全龍隊復出短短3年就打進總冠軍賽，今晚在第7戰以6：3擊敗樂天桃猿隊拿下隊史第5冠，天母棒球場漫天鮮紅色彩帶飛舞，補起了中斷20年的歲月，追平新軍最速奪冠紀錄。",
        "新店裕隆城規劃以來眾人引頸企盼，房價跟著一路漲，依據實價登錄資料，不只剛性需求一般住宅上漲，周邊高總價的社區增值空間更是驚人。其中位於寶強路的「合環御寶」，今年3筆轉手交易都增值，其中中高樓層一戶，總面積約108坪，今年以總價7,800萬元轉手，持有9年大賺1,200萬元。「合環御寶」另外2筆交易雖然增值沒有這麼多，但也分別有920萬、691萬的增值，而增值691萬元這筆，註明是親友交易，可能因此增值空間較小。不僅「合環御寶」今年轉售獲利亮眼，位在寶橋路的「寶徠花園」中高樓也有一戶以5688萬元轉手，持有10年獲利1,620萬元。大家房屋企畫研究室總監郎美囡表示，新店裕隆城周邊原本的生活機能就相當成熟，其靠近捷運七張站，原本就有家樂福、寶雅等賣場，商家林立，學區也很完整，也鄰近新店產業園區，因此在地有強勁的自住需求。今年雖然整體買氣不佳，但生活便利性高的蛋黃區房價仍然上揚，尤其裕隆城開幕，除了帶入就業人口，誠品旗艦店進駐添加光彩，周邊高總價住宅的價格成長空間完全不輸雙北其它強勢區。"
    ]

    # 文本向量化：將文本數據轉換為數字向量，以進行機器學習處理
    vectorizer = CountVectorizer()
    X = vectorizer.fit_transform(docs)

    # 建立LDA模型：LDA用於識別文件集中的隱藏主題
    # n_components設定主題的數量
    lda = LatentDirichletAllocation(n_components=3)  
    lda.fit(X)  # 訓練LDA模型

    # 建立函數來顯示每個主題下的主要詞彙
    def display_topics(model, feature_names, no_top_words):
        for topic_idx, topic in enumerate(model.components_):
            print(f"主題 {topic_idx+1}:")
            print(" ".join([feature_names[i]
                            for i in topic.argsort()[:-no_top_words - 1:-1]]))

    # 設定顯示每個主題的前N個詞彙
    no_top_words = 2

    # 取得詞彙名稱
    tf_feature_names = vectorizer.get_feature_names_out()

    # 顯示主題
    display_topics(lda, tf_feature_names, no_top_words)
    ```
    _主題建模結果_
    ```bash
    主題 1:
    停卡之前最晚何時要通知持卡人 否則到清卡時
    主題 2:
    合環御寶 因此在地有強勁的自住需求
    主題 3:
    龍迷終於流下喜悅的淚水 追平新軍最速奪冠紀錄
    ```

<br>

4. 補充說明一下範例中的 `LDA` ，在 scikit-learn 中的 LDA 模型有兩個，分別是 `隱含狄利克雷分配（Latent Dirichlet Allocation）` 與 `線性判別分析（Linear Discriminant Analysis）` ，使用上會根據具體需求選擇適當的模型，如果目標是文本分析並從文件中提取主題，則使用隱含狄利克雷分配；如果目標是分類或降維，則選擇線性判別分析。


<br>

## 主題建模的應用

_主題建模在自然語言處理（NLP）和文本分析領域中扮演著重要的角色。_

<br>

1. 揭示隱藏主題：主題建模能夠從大量文本數據中自動識別和提取出隱藏的主題或概念，這些主題可能不是直接顯而易見的。

<br>

2. 文本分類和組織：通過識別文本中的主題，主題建模有助於對文件進行分類和組織，從而改善信息檢索和文件管理。

<br>

3. 信息摘要和趨勢分析：主題建模可以用於生成文本摘要或識別文本集中的趨勢和模式，對於新聞聚合、社交媒體分析和市場研究等領域尤為有用。

<br>

4. 改善搜索引擎效果：在搜索引擎和推薦系統中，主題建模可以用於增強相關性模型，提供更準確的搜索結果和推薦。

<br>

5. 內容推薦：在內容推薦系統中，主題建模可以幫助識別用戶的興趣點和偏好，從而提供更個性化的內容推薦。

<br>

6. 洞察取得：對於研究人員和數據分析師，主題建模提供了一種探索和理解大規模文本集的方法，有助於從數據中取得洞察和知識。


<br>

---

_END_